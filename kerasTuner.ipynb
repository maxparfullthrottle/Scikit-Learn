{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kerasTuner.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP0jDgQ7sFn0nezV2kId3TW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maxparfullthrottle/Scikit-Learn/blob/master/kerasTuner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8AvfCtm0ozc",
        "outputId": "2b5ab741-1021-4347-8aa3-56a7241a03c9"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import keras\n",
        "print(keras.__version__)\n",
        "!pip install keras-tuner\n",
        "import kerastuner\n",
        "print(kerastuner.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n",
            "2.4.3\n",
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (20.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.8.9)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->keras-tuner) (1.0.1)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-cp37-none-any.whl size=78938 sha256=683e7d2c53f1e4af9782920d2adc20a59d27ff0eb1a500336965b529795228cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a1/8a/7c3de0efb3707a1701b36ebbfdbc4e67aedf6d4943a1f463d6\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp37-none-any.whl size=15356 sha256=11037f568a64118a8c19e1fca24601b39eab5def128f439374bc0e11086cdc1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.4 keras-tuner-1.0.2 terminaltables-3.1.0\n",
            "1.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wz32HNWC2zAs",
        "outputId": "93fe418d-a3cf-4ec3-bf24-ab0102f8ceef"
      },
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()   #get the data\n",
        "\n",
        "print(x_train.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "DdTUj9FN4RRR",
        "outputId": "6248cdba-8c8d-44fe-cab8-95c7b4ec2904"
      },
      "source": [
        "#Visualize the data\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "print(y_test[0])\n",
        "plt.imshow(x_test[0], cmap=\"gray\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff0eeb9e590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTIs0KI34cC6"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Activation\n",
        "#Now we will reshape the input data for input to a convolutional neural network:\n",
        "\n",
        "x_train = x_train.reshape(-1, 28, 28,1)\n",
        "x_test = x_test.reshape(-1, 28, 28,1)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oy484Ci27UoO",
        "outputId": "919f8b7f-e0b9-4985-ae60-7ea0e04c677f"
      },
      "source": [
        "def build_model():  \n",
        "    model = keras.models.Sequential()\n",
        "    \n",
        "    model.add(Conv2D(32, (3, 3), input_shape=x_train.shape[1:]))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten()) \n",
        "\n",
        "    model.add(Dense(10))\n",
        "    model.add(Activation(\"softmax\"))\n",
        "\n",
        "    model.compile(optimizer=\"adam\",\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "model.fit(x_train,y_train, 32, 5, validation_data=(x_test,y_test), verbose=1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 44s 23ms/step - loss: 1.2475 - accuracy: 0.7358 - val_loss: 0.4303 - val_accuracy: 0.8470\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 43s 23ms/step - loss: 0.3936 - accuracy: 0.8591 - val_loss: 0.4057 - val_accuracy: 0.8578\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 43s 23ms/step - loss: 0.3447 - accuracy: 0.8737 - val_loss: 0.3732 - val_accuracy: 0.8716\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 43s 23ms/step - loss: 0.3261 - accuracy: 0.8809 - val_loss: 0.3553 - val_accuracy: 0.8703\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 43s 23ms/step - loss: 0.3039 - accuracy: 0.8885 - val_loss: 0.3556 - val_accuracy: 0.8759\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff0eea7c0d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUgkL0cm-Ngd"
      },
      "source": [
        "from kerastuner.tuners import RandomSearch\n",
        "from kerastuner.engine.hyperparameters import HyperParameters\n",
        "\n",
        "import time\n",
        "LOG_DIR = f\"{int(time.time())}\" #create a timebound ddirectory"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkZ-Lkkq_HXG"
      },
      "source": [
        "# The final code examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGGBB-u--pRd"
      },
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Activation\n",
        "from tensorflow.keras import layers\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from kerastuner.engine.hyperparameters import HyperParameters\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "LOG_DIR = f\"{int(time.time())}\"\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=LOG_DIR)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "DkJdkeBlCYN0",
        "outputId": "849df57c-2853-4295-cf52-94e5ac6a7920"
      },
      "source": [
        "'''\n",
        "Label   Description\n",
        "0   T-shirt/top\n",
        "1   Trouser\n",
        "2   Pullover\n",
        "3   Dress\n",
        "4   Coat\n",
        "5   Sandal\n",
        "6   Shirt\n",
        "7   Sneaker\n",
        "8   Bag\n",
        "9   Ankle boot'''"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nLabel   Description\\n0   T-shirt/top\\n1   Trouser\\n2   Pullover\\n3   Dress\\n4   Coat\\n5   Sandal\\n6   Shirt\\n7   Sneaker\\n8   Bag\\n9   Ankle boot'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALZJSIzkCf0r",
        "outputId": "30c13c6b-936e-4042-9ea8-26fbf3ac778f"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)  # reshaping for convnet\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)  # reshaping for convnet\n",
        "\n",
        "\n",
        "def build_auto_model(hp):  # random search passes this hyperparameter() object \n",
        "    model = keras.models.Sequential()\n",
        "\n",
        "    model.add(Conv2D(hp.Int('input_units',\n",
        "                                min_value=32,\n",
        "                                max_value=256,\n",
        "                                step=32), (3, 3), input_shape=x_train.shape[1:]))\n",
        "\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    for i in range(hp.Int('n_layers', 1, 4)):  # adding variation of layers.\n",
        "        model.add(Conv2D(hp.Int(f'conv_{i}_units',\n",
        "                                min_value=32,\n",
        "                                max_value=256,\n",
        "                                step=32), (3, 3)))\n",
        "        model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Flatten()) \n",
        "    model.add(Dense(10))\n",
        "    model.add(Activation(\"softmax\"))\n",
        "\n",
        "    model.compile(optimizer=\"adam\",\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    build_auto_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=20,  # how many variations on model?\n",
        "    executions_per_trial=2,  # how many trials per variation? (same model could perform differently)\n",
        "    directory=LOG_DIR)\n",
        "\n",
        "tuner.search_space_summary()\n",
        "\n",
        "tuner.search(x=x_train,\n",
        "             y=y_train,\n",
        "             epochs=3,\n",
        "             batch_size=64,\n",
        "             callbacks=[tensorboard],\n",
        "             validation_data=(x_test, y_test))\n",
        "\n",
        "tuner.results_summary()\n",
        "\n",
        "with open(f\"tuner_{int(time.time())}.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tuner, f)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 20 Complete [00h 00m 48s]\n",
            "val_accuracy: 0.893449991941452\n",
            "\n",
            "Best val_accuracy So Far: 0.8973999917507172\n",
            "Total elapsed time: 00h 15m 19s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Results summary\n",
            "Results in 1616229084/untitled_project\n",
            "Showing 10 best trials\n",
            "Objective(name='val_accuracy', direction='max')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "input_units: 160\n",
            "n_layers: 3\n",
            "conv_0_units: 128\n",
            "conv_1_units: 256\n",
            "conv_2_units: 160\n",
            "conv_3_units: 32\n",
            "Score: 0.8973999917507172\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "input_units: 192\n",
            "n_layers: 2\n",
            "conv_0_units: 96\n",
            "conv_1_units: 128\n",
            "conv_2_units: 128\n",
            "Score: 0.8944000005722046\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "input_units: 224\n",
            "n_layers: 2\n",
            "conv_0_units: 256\n",
            "conv_1_units: 192\n",
            "conv_2_units: 64\n",
            "conv_3_units: 160\n",
            "Score: 0.8935500085353851\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "input_units: 128\n",
            "n_layers: 2\n",
            "conv_0_units: 192\n",
            "conv_1_units: 160\n",
            "conv_2_units: 96\n",
            "conv_3_units: 128\n",
            "Score: 0.893449991941452\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "input_units: 32\n",
            "n_layers: 3\n",
            "conv_0_units: 128\n",
            "conv_1_units: 224\n",
            "conv_2_units: 32\n",
            "Score: 0.8912500143051147\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "input_units: 96\n",
            "n_layers: 2\n",
            "conv_0_units: 192\n",
            "conv_1_units: 96\n",
            "conv_2_units: 160\n",
            "conv_3_units: 224\n",
            "Score: 0.8895500004291534\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "input_units: 64\n",
            "n_layers: 3\n",
            "conv_0_units: 192\n",
            "conv_1_units: 96\n",
            "conv_2_units: 192\n",
            "Score: 0.8891499936580658\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "input_units: 96\n",
            "n_layers: 4\n",
            "conv_0_units: 96\n",
            "conv_1_units: 128\n",
            "conv_2_units: 256\n",
            "conv_3_units: 96\n",
            "Score: 0.8885499835014343\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "input_units: 96\n",
            "n_layers: 4\n",
            "conv_0_units: 64\n",
            "conv_1_units: 192\n",
            "conv_2_units: 96\n",
            "conv_3_units: 224\n",
            "Score: 0.8876000046730042\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "input_units: 64\n",
            "n_layers: 3\n",
            "conv_0_units: 32\n",
            "conv_1_units: 96\n",
            "conv_2_units: 96\n",
            "Score: 0.8867500126361847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXQzHlp4Eq8C",
        "outputId": "8c668e27-42c5-443f-ad86-ae77aee383f1"
      },
      "source": [
        "tuner.get_best_models()[0].summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 160)       1600      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 26, 26, 160)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 160)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 128)       184448    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 9, 9, 256)         295168    \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 9, 9, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 7, 7, 160)         368800    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 7, 7, 160)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 7840)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                78410     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 928,426\n",
            "Trainable params: 928,426\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}